# OpenAI-Gym

I am playing with some of the OpenAI Gym environments to learn about reinforcement learning. Much of the code that I am using right now is borrowed and is not my own (though this is quickly changing).

Cartpole is one of the easiest gym environments, while MountinCar is notoriously hard. "The MountainCar environment is hard partly because there's a limit of 200 timesteps after which it resets to the beginning. Successful agents must solve it in less than 200 timesteps" (https://github.com/openai/gym/wiki/FAQ). 